{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d8ff7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CONFIG:\n",
      "    input_type: markers\n",
      "    output_size: 5\n",
      "    n_observed_classes: 5\n",
      "    n_aug_classes: 2\n",
      "    expt_ids: ['2019_08_07_fly2', '2019_08_08_fly1', '2019_08_20_fly2', '2019_10_10_fly3', '2019_10_14_fly3']\n",
      "    data_dir: /home/bsb2144/daart/daart_utils/data/fly/\n",
      "    results_dir: /home/bsb2144/daart/results_gmdgm/\n",
      "\n",
      "MODEL CONFIG:\n",
      "    model_class: rslds\n",
      "    backbone: dtcn\n",
      "    backbone_inference: dtcn\n",
      "    backbone_generative: dtcn\n",
      "    n_hid_layers: 2\n",
      "    n_hid_units: 32\n",
      "    n_lags: 4\n",
      "    activation: lrelu\n",
      "    bidirectional: True\n",
      "    dropout: 0.1\n",
      "    classifier_type: multiclass\n",
      "    lambda_weak: 0\n",
      "    lambda_strong: 100\n",
      "    lambda_recon: 0\n",
      "    lambda_pred: 1\n",
      "    lambda_task: 0\n",
      "    tt_experiment_name: test_rslds_50_y\n",
      "    rng_seed_model: 0\n",
      "    variational: False\n",
      "    anneal_start: 25\n",
      "    anneal_end: 125\n",
      "    anneal_start_y: 25\n",
      "    anneal_end_y: 125\n",
      "    kl_weight: 0.1\n",
      "    kl_y_weight: 10\n",
      "    semi_supervised_algo: None\n",
      "    prob_threshold: 0.9\n",
      "\n",
      "TRAIN CONFIG:\n",
      "    learning_rate: 0.0001\n",
      "    sequence_length: 500\n",
      "    batch_size: 2\n",
      "    l2_reg: 0\n",
      "    min_epochs: 400\n",
      "    max_epochs: 600\n",
      "    val_check_interval: 1\n",
      "    enable_early_stop: True\n",
      "    early_stop_history: 5\n",
      "    save_last_model: False\n",
      "    train_frac: 1\n",
      "    trial_splits: 9;1;0;0\n",
      "    rng_seed_train: 0\n",
      "    plot_train_curves: True\n",
      "    device: cpu\n",
      "    gpus_vis: 0\n",
      "    tt_n_cpu_trials: 100\n",
      "    tt_n_cpu_workers: 5\n",
      "\n",
      "\n",
      "Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "Generator contains 5 SingleDataset objects:\n",
      "2019_08_07_fly2\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_07_fly2_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_07_fly2_labels.csv')])\n",
      "2019_08_08_fly1\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_08_fly1_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_08_fly1_labels.csv')])\n",
      "2019_08_20_fly2\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_20_fly2_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_20_fly2_labels.csv')])\n",
      "2019_10_10_fly3\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_10_10_fly3_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_10_10_fly3_labels.csv')])\n",
      "2019_10_14_fly3\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_10_14_fly3_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_10_14_fly3_labels.csv')])\n",
      "\n",
      "using rslds\n",
      "probs [0.01, 0.3465, 0.3465, 0.07425, 0.07425, 0.07425, 0.07425]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 336, in getMessage\n",
      "    msg = str(self.msg)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 271, in __str__\n",
      "    format_str += self.generative.__str__()\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 141, in __str__\n",
      "    for i, module in enumerate(self.model['pz_t_logvar']):\n",
      "TypeError: 'DilatedTCN' object is not iterable\n",
      "Call stack:\n",
      "  File \"fit_models.py\", line 162, in <module>\n",
      "    nb_workers=hyperparams.tt_n_cpu_workers)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 389, in optimize_parallel_cpu\n",
      "    self.pool = Pool(processes=nb_workers)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 61, in optimize_parallel_cpu_private\n",
      "    results = train_function(trial_params)\n",
      "  File \"fit_models.py\", line 45, in run_main\n",
      "    train_model(hparams)\n",
      "  File \"fit_models.py\", line 79, in train_model\n",
      "    logging.info(model)\n",
      "Message: RSLDS(\n",
      "  (model): ModuleDict(\n",
      "    (qy_x): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (qz_xy_mean): Sequential(\n",
      "      (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (qz_xy_logvar): Sequential(\n",
      "      (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (py_t_probs): Sequential(\n",
      "      (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "    )\n",
      "    (pz_t_mean): Sequential(\n",
      "      (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (pz_t_logvar): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inference): BaseInference(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generative): RSLDSGenerative(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_loss): CrossEntropyLoss()\n",
      "  (recon_loss): MSELoss()\n",
      ")\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 336, in getMessage\n",
      "    msg = str(self.msg)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 271, in __str__\n",
      "    format_str += self.generative.__str__()\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 141, in __str__\n",
      "    for i, module in enumerate(self.model['pz_t_logvar']):\n",
      "TypeError: 'DilatedTCN' object is not iterable\n",
      "Call stack:\n",
      "  File \"fit_models.py\", line 162, in <module>\n",
      "    nb_workers=hyperparams.tt_n_cpu_workers)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 389, in optimize_parallel_cpu\n",
      "    self.pool = Pool(processes=nb_workers)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 61, in optimize_parallel_cpu_private\n",
      "    results = train_function(trial_params)\n",
      "  File \"fit_models.py\", line 45, in run_main\n",
      "    train_model(hparams)\n",
      "  File \"fit_models.py\", line 79, in train_model\n",
      "    logging.info(model)\n",
      "Message: RSLDS(\n",
      "  (model): ModuleDict(\n",
      "    (qy_x): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (qz_xy_mean): Sequential(\n",
      "      (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (qz_xy_logvar): Sequential(\n",
      "      (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (py_t_probs): Sequential(\n",
      "      (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "    )\n",
      "    (pz_t_mean): Sequential(\n",
      "      (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (pz_t_logvar): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inference): BaseInference(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generative): RSLDSGenerative(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_loss): CrossEntropyLoss()\n",
      "  (recon_loss): MSELoss()\n",
      ")\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████▋            | 401/601 [2:16:43<1:09:17, 20.79s/it]\n",
      "== early stopping criteria met; exiting train loop ==\n",
      "training epochs: 401\n",
      "end cost: 27.000360\n",
      "best epoch: 370\n",
      "best cost: 25.746389\n",
      "\n",
      " 67%|████████████████████████▋            | 401/601 [2:17:04<1:08:21, 20.51s/it]\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.5.\n",
      "findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 3.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 3.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 2.24\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 2.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 2.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.5 to DejaVu Sans ('/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 2.050000.\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=18.0.\n",
      "findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 3.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 3.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 2.24\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 2.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 2.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=18.0 to DejaVu Sans ('/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 2.050000.\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n"
     ]
    }
   ],
   "source": [
    "!python fit_models.py --data_config \"/home/bsb2144/daart/daart_utils/configs/data_fly.yaml\" --model_config \"/home/bsb2144/daart/daart_utils/configs/model.yaml\" --train_config \"/home/bsb2144/daart/daart_utils/configs/train_fly.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "392a6cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CONFIG:\n",
      "    input_type: markers\n",
      "    output_size: 5\n",
      "    n_observed_classes: 5\n",
      "    n_aug_classes: 0\n",
      "    ignore_class: 0\n",
      "    expt_ids: ['ssm_v1']\n",
      "    data_dir: /home/bsb2144/daart/daart_utils/data/ssm/\n",
      "    results_dir: /home/bsb2144/daart/results_gmdgm/\n",
      "\n",
      "MODEL CONFIG:\n",
      "    model_class: rslds\n",
      "    backbone: dtcn\n",
      "    backbone_inference: dtcn\n",
      "    backbone_generative: dtcn\n",
      "    n_hid_layers: 2\n",
      "    n_hid_units: 2\n",
      "    n_lags: 4\n",
      "    activation: lrelu\n",
      "    bidirectional: True\n",
      "    dropout: 0.1\n",
      "    classifier_type: multiclass\n",
      "    lambda_weak: 0\n",
      "    lambda_strong: 12\n",
      "    lambda_recon: 0\n",
      "    lambda_pred: 1\n",
      "    lambda_task: 0\n",
      "    tt_experiment_name: no_class_v3\n",
      "    rng_seed_model: 0\n",
      "    variational: False\n",
      "    anneal_start: 25\n",
      "    anneal_end: 125\n",
      "    anneal_start_y: 25\n",
      "    anneal_end_y: 125\n",
      "    kl_weight: 0.1\n",
      "    kl_y_weight: 10\n",
      "    semi_supervised_algo: None\n",
      "    prob_threshold: 0.9\n",
      "\n",
      "TRAIN CONFIG:\n",
      "    learning_rate: 0.0001\n",
      "    sequence_length: 500\n",
      "    batch_size: 2\n",
      "    l2_reg: 0\n",
      "    min_epochs: 400\n",
      "    max_epochs: 600\n",
      "    val_check_interval: 1\n",
      "    enable_early_stop: True\n",
      "    early_stop_history: 5\n",
      "    save_last_model: False\n",
      "    train_frac: 1\n",
      "    trial_splits: 9;1;0;0\n",
      "    rng_seed_train: 0\n",
      "    plot_train_curves: True\n",
      "    device: cpu\n",
      "    gpus_vis: 0\n",
      "    tt_n_cpu_trials: 100\n",
      "    tt_n_cpu_workers: 5\n",
      "\n",
      "\n",
      "Generator contains 1 SingleDataset objects:\n",
      "ssm_v1\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/ssm/markers/ssm_v1_labeled.npy'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/ssm/labels-hand/ssm_v1_labels.csv')])\n",
      "\n",
      "using rslds\n",
      "probs [1e-05, 0.1, 0.4, 0.4, 0.1]\n",
      "\n",
      "\n",
      "Inference model\n",
      "Inference network architecture: DTCN\n",
      "------------------------\n",
      "Encoder (q(z|x,y)):\n",
      "    0: DilationBlock\n",
      "        0: Conv1d(15, 2, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "    1: DilationBlock\n",
      "        0: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "\n",
      "q(y|x):\n",
      "    0: DilationBlock\n",
      "        0: Conv1d(10, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "    1: DilationBlock\n",
      "        0: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 5, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "    2: Conv1d(5, 5, kernel_size=(1,), stride=(1,))\n",
      "\n",
      "q(z|xy) mean:\n",
      "    0: Linear(in_features=2, out_features=2, bias=True)\n",
      "q(z|xy) logvar:\n",
      "    0: Linear(in_features=2, out_features=2, bias=True)\n",
      "------------------------\n",
      "\n",
      "\n",
      "Generative model\n",
      "Generative network architecture: DTCN\n",
      "------------------------\n",
      "Decoder (p(x_t|z_t)):\n",
      "    0: DilationBlock\n",
      "        0: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "    1: DilationBlock\n",
      "        0: Conv1d(2, 2, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        1: LeakyReLU(negative_slope=0.05)\n",
      "        2: Dropout2d(p=0.1, inplace=False)\n",
      "        3: Conv1d(2, 10, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "        4: LeakyReLU(negative_slope=0.05)\n",
      "        5: Dropout2d(p=0.1, inplace=False)\n",
      "        6: residual connection\n",
      "        7: LeakyReLU(negative_slope=0.05)\n",
      "\n",
      "    2: Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "\n",
      "p(y_t|y_(t-1), z_(t-1)):\n",
      "    0: Linear(in_features=2, out_features=25, bias=True)\n",
      "\n",
      "p(z_t|z_(t-1), y_t) mean:\n",
      "    0: Linear(in_features=2, out_features=10, bias=True)\n",
      " Weights: Parameter containing:\n",
      "tensor([[-0.4125,  0.0684],\n",
      "        [-0.5369, -0.2074],\n",
      "        [-0.2775,  0.6198],\n",
      "        [-0.6365, -0.4175],\n",
      "        [-0.6920,  0.1783],\n",
      "        [-0.5443,  0.2288],\n",
      "        [-0.4912, -0.4530],\n",
      "        [-0.3612,  0.1061],\n",
      "        [ 0.6497,  0.6624],\n",
      "        [-0.0534, -0.6926]], requires_grad=True)\n",
      "\n",
      " 69%|████████████████████████████▍            | 416/601 [01:42<00:48,  3.78it/s]\n",
      "== early stopping criteria met; exiting train loop ==\n",
      "training epochs: 416\n",
      "end cost: 21.124068\n",
      "best epoch: 411\n",
      "best cost: 21.119721\n",
      "\n",
      " 69%|████████████████████████████▍            | 416/601 [01:42<00:45,  4.06it/s]\n",
      "Note: NumExpr detected 64 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.5.\n",
      "findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 3.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 3.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 2.24\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 2.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 2.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.5 to DejaVu Sans ('/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 2.050000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=18.0.\n",
      "findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05\n",
      "findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335\n",
      "findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-BoldOblique.ttf) oblique normal 700 condensed>) = 3.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Oblique.ttf) oblique normal 400 condensed>) = 3.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-ExtraLight.ttf) normal normal 200 normal>) = 2.24\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 2.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 3.05\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed.ttf) normal normal 400 condensed>) = 2.25\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSansCondensed-Bold.ttf) normal normal 700 condensed>) = 2.535\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 3.335\n",
      "findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 2.05\n",
      "findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=18.0 to DejaVu Sans ('/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 2.050000.\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n",
      "top of axes not in the figure, so title not moved\n"
     ]
    }
   ],
   "source": [
    "# ssm data\n",
    "!python fit_models.py --data_config \"/home/bsb2144/daart/daart_utils/configs/data_ssm.yaml\" --model_config \"/home/bsb2144/daart/daart_utils/configs/model_ssm.yaml\" --train_config \"/home/bsb2144/daart/daart_utils/configs/train_ssm.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85715776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init shape torch.Size([3, 3])\n",
      "inds tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 0]]) torch.Size([3, 2])\n",
      "test torch.Size([3, 3, 2])\n",
      "test post torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 0, 0], [0,1,0], [1, 0, 0]])\n",
    "print('init shape', t.shape)\n",
    "inds = ((t == 1).nonzero())\n",
    "print('inds', inds, inds.shape)\n",
    "\n",
    "test = torch.rand(3,3,2)\n",
    "print('test', test.shape)\n",
    "#test = test.gather(dim=1, index=inds)\n",
    "print('test post', test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f20aac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids torch.Size([2, 547, 1, 7])\n",
      "out torch.Size([2, 547, 7])\n",
      "y tensor([ 1.2248,  0.8699, -0.6025, -0.4589, -0.7243, -2.5641,  0.8766,  0.6104])\n",
      "test tensor([[ 8.9098e-01,  3.8697e-01, -4.0794e-01, -4.3829e-01, -2.7518e+00,\n",
      "         -3.8309e-01,  1.1498e+00],\n",
      "        [ 1.6185e-01,  4.8711e-02,  1.3151e-01,  8.4871e-01, -4.3701e-01,\n",
      "         -1.4579e+00,  4.5584e-01],\n",
      "        [-1.8820e+00, -2.2591e+00, -8.4416e-02,  1.6561e-01, -1.2381e+00,\n",
      "          5.2530e-01, -6.0445e-01],\n",
      "        [-5.9338e-02, -1.3315e+00, -1.1808e-01,  1.3968e-01,  3.7804e-01,\n",
      "          8.5107e-01,  3.5389e-01],\n",
      "        [ 1.3915e+00,  1.7394e+00, -1.8596e+00, -2.0370e+00, -1.5370e+00,\n",
      "          8.9875e-01,  2.5290e-01],\n",
      "        [-6.8865e-01, -2.2543e-01, -5.3145e-01,  2.0899e-01,  2.0684e-03,\n",
      "         -6.6604e-01, -1.5221e+00],\n",
      "        [-5.5776e-01, -1.1395e+00, -8.3014e-01, -1.3172e+00,  7.7618e-01,\n",
      "          2.4171e+00,  7.0463e-01],\n",
      "        [-6.5419e-01,  2.3174e-01, -4.5497e-01, -2.6838e-01, -1.9267e+00,\n",
      "          8.6991e-01,  1.2138e-02]])\n",
      "out tensor([ 0.8910,  0.3870, -0.4079, -0.4383, -2.7518, -0.3831,  1.1498])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = torch.randn(2, 547, 8)\n",
    "test = torch.randn(2, 547, 8, 7)\n",
    "indexer = y.argmax(2,True).unsqueeze(-1).expand(*(-1,)*y.ndim, test.shape[3])\n",
    "\n",
    "print('ids', indexer.shape)\n",
    "\n",
    "out = torch.gather(test, 2, indexer).squeeze(2)\n",
    "\n",
    "\n",
    "print('out', out.shape)\n",
    "\n",
    "print('y', y[0,0])\n",
    "print('test', test[0,0])\n",
    "\n",
    "print('out', out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6571270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daart)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
