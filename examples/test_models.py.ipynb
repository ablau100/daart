{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39d8ff7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CONFIG:\n",
      "    input_type: markers\n",
      "    output_size: 5\n",
      "    n_observed_classes: 5\n",
      "    n_aug_classes: 2\n",
      "    expt_ids: ['2019_08_07_fly2', '2019_08_08_fly1', '2019_08_20_fly2', '2019_10_10_fly3', '2019_10_14_fly3']\n",
      "    data_dir: /home/bsb2144/daart/daart_utils/data/fly/\n",
      "    results_dir: /home/bsb2144/daart/results_gmdgm/\n",
      "\n",
      "MODEL CONFIG:\n",
      "    model_class: rslds\n",
      "    backbone: dtcn\n",
      "    backbone_inference: dtcn\n",
      "    backbone_generative: dtcn\n",
      "    n_hid_layers: 2\n",
      "    n_hid_units: 32\n",
      "    n_lags: 4\n",
      "    activation: lrelu\n",
      "    bidirectional: True\n",
      "    dropout: 0.1\n",
      "    classifier_type: multiclass\n",
      "    lambda_weak: 0\n",
      "    lambda_strong: 100\n",
      "    lambda_recon: 0\n",
      "    lambda_pred: 1\n",
      "    lambda_task: 0\n",
      "    tt_experiment_name: test_reparam_v2\n",
      "    rng_seed_model: 0\n",
      "    variational: False\n",
      "    anneal_start: 25\n",
      "    anneal_end: 125\n",
      "    anneal_start_y: 25\n",
      "    anneal_end_y: 125\n",
      "    kl_weight: 0.1\n",
      "    kl_y_weight: 10\n",
      "    semi_supervised_algo: None\n",
      "    prob_threshold: 0.9\n",
      "\n",
      "TRAIN CONFIG:\n",
      "    learning_rate: 0.0001\n",
      "    sequence_length: 500\n",
      "    batch_size: 2\n",
      "    l2_reg: 0\n",
      "    min_epochs: 10\n",
      "    max_epochs: 60\n",
      "    val_check_interval: 1\n",
      "    enable_early_stop: True\n",
      "    early_stop_history: 5\n",
      "    save_last_model: False\n",
      "    train_frac: 1\n",
      "    trial_splits: 9;1;0;0\n",
      "    rng_seed_train: 0\n",
      "    plot_train_curves: True\n",
      "    device: cuda\n",
      "    gpus_vis: 0\n",
      "    tt_n_cpu_trials: 100\n",
      "    tt_n_cpu_workers: 5\n",
      "\n",
      "\n",
      "Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "Generator contains 5 SingleDataset objects:\n",
      "2019_08_07_fly2\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_07_fly2_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_07_fly2_labels.csv')])\n",
      "2019_08_08_fly1\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_08_fly1_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_08_fly1_labels.csv')])\n",
      "2019_08_20_fly2\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_08_20_fly2_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_08_20_fly2_labels.csv')])\n",
      "2019_10_10_fly3\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_10_10_fly3_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_10_10_fly3_labels.csv')])\n",
      "2019_10_14_fly3\n",
      "    signals: ['markers', 'labels_strong']\n",
      "    transforms: OrderedDict([('markers', ZScore()), ('labels_strong', None)])\n",
      "    paths: OrderedDict([('markers', '/home/bsb2144/daart/daart_utils/data/fly/markers/2019_10_14_fly3_labeled.h5'), ('labels_strong', '/home/bsb2144/daart/daart_utils/data/fly/labels-hand/2019_10_14_fly3_labels.csv')])\n",
      "\n",
      "using rslds\n",
      "probs [0.01    0.3465  0.3465  0.07425 0.07425 0.07425 0.07425]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 336, in getMessage\n",
      "    msg = str(self.msg)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 275, in __str__\n",
      "    format_str += self.generative.__str__()\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 141, in __str__\n",
      "    for i, module in enumerate(self.model['pz_t_logvar']):\n",
      "TypeError: 'DilatedTCN' object is not iterable\n",
      "Call stack:\n",
      "  File \"fit_models.py\", line 156, in <module>\n",
      "    gpu_ids=gpu_ids)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 322, in optimize_parallel_gpu\n",
      "    self.pool = Pool(processes=nb_workers, initializer=init, initargs=(gpu_q,))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 39, in optimize_parallel_gpu_private\n",
      "    results = train_function(trial_params, gpu_id_set)\n",
      "  File \"fit_models.py\", line 45, in run_main\n",
      "    train_model(hparams)\n",
      "  File \"fit_models.py\", line 79, in train_model\n",
      "    logging.info(model)\n",
      "Message: RSLDS(\n",
      "  (model): ModuleDict(\n",
      "    (qy_x): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (qz_xy_mean): Sequential(\n",
      "      (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (qz_xy_logvar): Sequential(\n",
      "      (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (py_t_probs): Sequential(\n",
      "      (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "    )\n",
      "    (pz_t_mean): Sequential(\n",
      "      (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (pz_t_logvar): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inference): BaseInference(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generative): RSLDSGenerative(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_loss): CrossEntropyLoss()\n",
      "  (recon_loss): MSELoss()\n",
      ")\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/logging/__init__.py\", line 336, in getMessage\n",
      "    msg = str(self.msg)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 275, in __str__\n",
      "    format_str += self.generative.__str__()\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 141, in __str__\n",
      "    for i, module in enumerate(self.model['pz_t_logvar']):\n",
      "TypeError: 'DilatedTCN' object is not iterable\n",
      "Call stack:\n",
      "  File \"fit_models.py\", line 156, in <module>\n",
      "    gpu_ids=gpu_ids)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 322, in optimize_parallel_gpu\n",
      "    self.pool = Pool(processes=nb_workers, initializer=init, initargs=(gpu_q,))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/test_tube/argparse_hopt.py\", line 39, in optimize_parallel_gpu_private\n",
      "    results = train_function(trial_params, gpu_id_set)\n",
      "  File \"fit_models.py\", line 45, in run_main\n",
      "    train_model(hparams)\n",
      "  File \"fit_models.py\", line 79, in train_model\n",
      "    logging.info(model)\n",
      "Message: RSLDS(\n",
      "  (model): ModuleDict(\n",
      "    (qy_x): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (encoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (qz_xy_mean): Sequential(\n",
      "      (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (qz_xy_logvar): Sequential(\n",
      "      (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (py_t_probs): Sequential(\n",
      "      (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "    )\n",
      "    (pz_t_mean): Sequential(\n",
      "      (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (pz_t_logvar): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): DilatedTCN(\n",
      "      (model): Sequential(\n",
      "        (tcn_block_00): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (tcn_block_01): DilationBlock(\n",
      "          (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (activation): LeakyReLU(negative_slope=0.05)\n",
      "          (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "          (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "          (block): Sequential(\n",
      "            (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "            (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "          )\n",
      "          (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inference): BaseInference(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generative): RSLDSGenerative(\n",
      "    (model): ModuleDict(\n",
      "      (qy_x): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 7, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 7, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (encoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(23, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(23, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (qz_xy_mean): Sequential(\n",
      "        (dense(qz_xy_mean)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (qz_xy_logvar): Sequential(\n",
      "        (dense(qz_xy_logvar)_layer_03): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (py_t_probs): Sequential(\n",
      "        (dense(py_t_probs)_layer_00): Linear(in_features=32, out_features=7, bias=True)\n",
      "      )\n",
      "      (pz_t_mean): Sequential(\n",
      "        (dense(pz_t_mean)_layer_00): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (pz_t_logvar): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(7, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(7, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DilatedTCN(\n",
      "        (model): Sequential(\n",
      "          (tcn_block_00): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (conv1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (tcn_block_01): DilationBlock(\n",
      "            (conv0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (conv1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "            (activation): LeakyReLU(negative_slope=0.05)\n",
      "            (final_activation): LeakyReLU(negative_slope=0.05)\n",
      "            (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "            (block): Sequential(\n",
      "              (conv1d_layer_0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_0): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_0): Dropout2d(p=0.1, inplace=False)\n",
      "              (conv1d_layer_1): Conv1d(32, 16, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "              (lrelu_1): LeakyReLU(negative_slope=0.05)\n",
      "              (dropout_1): Dropout2d(p=0.1, inplace=False)\n",
      "            )\n",
      "            (downsample): Conv1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (final_dense_02): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_loss): CrossEntropyLoss()\n",
      "  (recon_loss): MSELoss()\n",
      ")\n",
      "Arguments: ()\n",
      "  0%|                                                    | 0/61 [00:00<?, ?it/s]pz log torch.Size([2, 548, 32])\n",
      "  0%|                                                    | 0/61 [00:00<?, ?it/s]\n",
      "error traceback\n",
      "Traceback (most recent call last):\n",
      "  File \"fit_models.py\", line 45, in run_main\n",
      "    train_model(hparams)\n",
      "  File \"fit_models.py\", line 110, in train_model\n",
      "    trainer.fit(model, data_gen, save_path=hparams['tt_version_dir'])\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/train.py\", line 373, in fit\n",
      "    loss_dict = model.training_step(data, accumulate_grad=True)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 376, in training_step\n",
      "    outputs_dict = self.forward(markers_wpad, labels_wpad)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 333, in forward\n",
      "    gen_outputs = self.generative(**gen_inputs)\n",
      "  File \"/home/bsb2144/miniconda3/envs/daart/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/share/ctn/users/bsb2144/daart/daart/models/rslds.py\", line 199, in forward\n",
      "    ppp\n",
      "NameError: name 'ppp' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python fit_models.py --data_config \"/home/bsb2144/daart/daart_utils/configs/data_fly.yaml\" --model_config \"/home/bsb2144/daart/daart_utils/configs/model.yaml\" --train_config \"/home/bsb2144/daart/daart_utils/configs/train_fly.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf143c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8719, -0.1612, -1.5021,  ..., -1.2906, -0.7753,  0.5781],\n",
      "         [ 1.4182,  0.1078, -0.8922,  ...,  0.5131, -0.2130,  0.4742],\n",
      "         [-1.0313,  0.7460,  0.6973,  ...,  1.1156, -1.0137,  0.0790],\n",
      "         ...,\n",
      "         [ 0.0748, -1.3303,  0.5638,  ..., -0.3164,  0.7592,  0.8994],\n",
      "         [ 0.5364, -0.2579,  1.2789,  ...,  0.8797, -0.1544,  0.6812],\n",
      "         [ 1.1501,  1.4058,  0.4825,  ...,  1.5629,  0.2529, -0.1183]]])\n",
      "first shape torch.Size([2, 548, 32])\n",
      "res shape torch.Size([2, 547, 32])\n",
      "tensor([[[ 1.4182,  0.1078, -0.8922,  ...,  0.5131, -0.2130,  0.4742],\n",
      "         [-1.0313,  0.7460,  0.6973,  ...,  1.1156, -1.0137,  0.0790],\n",
      "         [-0.4723,  1.7023,  1.1306,  ..., -1.5797, -1.2598, -1.0121],\n",
      "         ...,\n",
      "         [ 0.0748, -1.3303,  0.5638,  ..., -0.3164,  0.7592,  0.8994],\n",
      "         [ 0.5364, -0.2579,  1.2789,  ...,  0.8797, -0.1544,  0.6812],\n",
      "         [ 1.1501,  1.4058,  0.4825,  ...,  1.5629,  0.2529, -0.1183]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "z = torch.randn(2, 548, 32)\n",
    "print(z[0:1])\n",
    "print('first shape', z.shape)\n",
    "\n",
    "res = z[:, 1:, :]\n",
    "\n",
    "print('res shape', res.shape)\n",
    "print(res[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b9be152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init shape torch.Size([3, 3])\n",
      "inds tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 0]]) torch.Size([3, 2])\n",
      "test torch.Size([3, 3, 2])\n",
      "test post torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 0, 0], [0,1,0], [1, 0, 0]])\n",
    "print('init shape', t.shape)\n",
    "inds = ((t == 1).nonzero())\n",
    "print('inds', inds, inds.shape)\n",
    "\n",
    "test = torch.rand(3,3,2)\n",
    "print('test', test.shape)\n",
    "#test = test.gather(dim=1, index=inds)\n",
    "print('test post', test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee74bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids torch.Size([2, 547, 1, 7])\n",
      "out torch.Size([2, 547, 7])\n",
      "y tensor([ 1.2248,  0.8699, -0.6025, -0.4589, -0.7243, -2.5641,  0.8766,  0.6104])\n",
      "test tensor([[ 8.9098e-01,  3.8697e-01, -4.0794e-01, -4.3829e-01, -2.7518e+00,\n",
      "         -3.8309e-01,  1.1498e+00],\n",
      "        [ 1.6185e-01,  4.8711e-02,  1.3151e-01,  8.4871e-01, -4.3701e-01,\n",
      "         -1.4579e+00,  4.5584e-01],\n",
      "        [-1.8820e+00, -2.2591e+00, -8.4416e-02,  1.6561e-01, -1.2381e+00,\n",
      "          5.2530e-01, -6.0445e-01],\n",
      "        [-5.9338e-02, -1.3315e+00, -1.1808e-01,  1.3968e-01,  3.7804e-01,\n",
      "          8.5107e-01,  3.5389e-01],\n",
      "        [ 1.3915e+00,  1.7394e+00, -1.8596e+00, -2.0370e+00, -1.5370e+00,\n",
      "          8.9875e-01,  2.5290e-01],\n",
      "        [-6.8865e-01, -2.2543e-01, -5.3145e-01,  2.0899e-01,  2.0684e-03,\n",
      "         -6.6604e-01, -1.5221e+00],\n",
      "        [-5.5776e-01, -1.1395e+00, -8.3014e-01, -1.3172e+00,  7.7618e-01,\n",
      "          2.4171e+00,  7.0463e-01],\n",
      "        [-6.5419e-01,  2.3174e-01, -4.5497e-01, -2.6838e-01, -1.9267e+00,\n",
      "          8.6991e-01,  1.2138e-02]])\n",
      "out tensor([ 0.8910,  0.3870, -0.4079, -0.4383, -2.7518, -0.3831,  1.1498])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = torch.randn(2, 547, 8)\n",
    "test = torch.randn(2, 547, 8, 7)\n",
    "indexer = y.argmax(2,True).unsqueeze(-1).expand(*(-1,)*y.ndim, test.shape[3])\n",
    "\n",
    "print('ids', indexer.shape)\n",
    "\n",
    "out = torch.gather(test, 2, indexer).squeeze(2)\n",
    "\n",
    "\n",
    "print('out', out.shape)\n",
    "\n",
    "print('y', y[0,0])\n",
    "print('test', test[0,0])\n",
    "\n",
    "print('out', out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805de43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daart)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
