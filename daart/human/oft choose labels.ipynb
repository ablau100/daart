{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from daart.data import DataGenerator, compute_sequence_pad\n",
    "from daart.eval import get_precision_recall, run_lengths\n",
    "from daart.io import get_expt_dir\n",
    "from daart.transforms import ZScore\n",
    "\n",
    "from daart_utils.data import DataHandler\n",
    "from daart_utils.models import compute_model_predictions, get_default_hparams\n",
    "#from daart_utils.paths import data_path, results_path\n",
    "from daart_utils.plotting import plot_heatmaps\n",
    "import ssm\n",
    "from ssm.util import random_rotation, find_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/home/bsb2144/daart_utils/data/mouse-oft-aligned/labels-hand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Background</th>\n",
       "      <th>Supported</th>\n",
       "      <th>Unsupported</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Background  Supported  Unsupported  Grooming  Other\n",
       "0           0          0            0         0      1\n",
       "1           0          0            0         0      1\n",
       "2           0          0            0         0      1\n",
       "3           0          0            0         0      1\n",
       "4           0          0            0         0      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oft data\n",
    "data = pd.read_csv(path + '/OFT_39_labels.csv', index_col=0)\n",
    "\n",
    "display(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = [\n",
    "    'OFT_5',\n",
    "    'OFT_6',\n",
    "    'OFT_11',\n",
    "    'OFT_12',\n",
    "    'OFT_14',\n",
    "    'OFT_15',\n",
    "    'OFT_16',\n",
    "    'OFT_23',\n",
    "    'OFT_24',\n",
    "    'OFT_38',\n",
    "    'OFT_39',\n",
    "    'OFT_41',\n",
    "    'OFT_43',\n",
    "    'OFT_44',\n",
    "    'OFT_49',\n",
    "    'OFT_50',\n",
    "    'OFT_51',\n",
    "    'OFT_52',\n",
    "    'OFT_54',\n",
    "    'OFT_58',\n",
    "]\n",
    "\n",
    "for vid in vids:\n",
    "    data = pd.read_csv(path + '/{}_labels.csv'.format(vid), index_col=0)\n",
    "    data['Background'] = data['Other']\n",
    "    data.drop('Other', axis=1, inplace=True)\n",
    "    data.to_csv(path + '/{}_labels.csv'.format(vid))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vids = [\n",
    "    'OFT_5',\n",
    "    'OFT_6',\n",
    "    'OFT_11',\n",
    "    'OFT_12',\n",
    "    'OFT_14',\n",
    "    'OFT_15',\n",
    "    'OFT_16',\n",
    "    'OFT_23',\n",
    "    'OFT_24',\n",
    "    'OFT_38',\n",
    "]\n",
    "\n",
    "train_dfs = []\n",
    "# load labels\n",
    "for s in train_vids:\n",
    "    #print('session ' + s)\n",
    "    lab_path = path + '/' + s + '_labels.csv'\n",
    "    lab_df = pd.read_csv(lab_path, index_col=0)\n",
    "    train_dfs.append(lab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_start_end_time(array, bg_class=[0], use=1, chunk_size=50):\n",
    "    labels = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    \n",
    "    frame_wise_labels = array.copy()\n",
    "    #print('pre', frame_wise_labels[:100])\n",
    "    frame_wise_labels[array != use] = 0\n",
    "    #print('post', frame_wise_labels[:100])\n",
    "    \n",
    "    last_label = frame_wise_labels[0]\n",
    "    if frame_wise_labels[0] not in bg_class:\n",
    "        labels.append(frame_wise_labels[0])\n",
    "        starts.append(0)\n",
    "    for i in range(len(frame_wise_labels)):\n",
    "        if frame_wise_labels[i] != last_label:\n",
    "            if frame_wise_labels[i] not in bg_class:\n",
    "                labels.append(frame_wise_labels[i])\n",
    "                starts.append(i)\n",
    "            if last_label not in bg_class:\n",
    "                ends.append(i)\n",
    "                \n",
    "            last_label = frame_wise_labels[i]\n",
    "            \n",
    "    if last_label not in bg_class:\n",
    "        ends.append(i + 1)\n",
    "        \n",
    "    ends = [e-chunk_size for e in ends]\n",
    "    lens = [e-s for e,s in zip(ends, starts)]\n",
    "    \n",
    "    to_del = []\n",
    "    for l, ln in enumerate(lens): \n",
    "        if ln < 1:\n",
    "            to_del.append(l)\n",
    "            \n",
    "    offset = 0\n",
    "    for l in to_del:\n",
    "        starts.pop(l-offset)\n",
    "        ends.pop(l-offset)\n",
    "        labels.pop(l-offset)\n",
    "        lens.pop(l-offset)\n",
    "        offset += 1\n",
    "            \n",
    "    lens = [e-s for e,s in zip(ends, starts)]\n",
    "    return (labels, starts, ends, lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL:  2000\n",
      "VERSION:  v1\n",
      "cl Supported\n",
      "num 2000.0\n",
      "cl Unsupported\n",
      "num 2000.0\n",
      "cl Grooming\n",
      "num 2000.0\n",
      "VERSION:  v2\n",
      "cl Supported\n",
      "num 2000.0\n",
      "cl Unsupported\n",
      "num 2000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v3\n",
      "cl Supported\n",
      "num 2000.0\n",
      "cl Unsupported\n",
      "num 2000.0\n",
      "cl Grooming\n",
      "num 2000.0\n",
      "VERSION:  v4\n",
      "cl Supported\n",
      "num 2000.0\n",
      "cl Unsupported\n",
      "num 2000.0\n",
      "cl Grooming\n",
      "num 1900.0\n",
      "VERSION:  v5\n",
      "cl Supported\n",
      "num 2000.0\n",
      "cl Unsupported\n",
      "num 2000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "GOAL:  3000\n",
      "VERSION:  v1\n",
      "cl Supported\n",
      "num 3000.0\n",
      "cl Unsupported\n",
      "num 3000.0\n",
      "cl Grooming\n",
      "num 1900.0\n",
      "VERSION:  v2\n",
      "cl Supported\n",
      "num 3000.0\n",
      "cl Unsupported\n",
      "num 3000.0\n",
      "cl Grooming\n",
      "num 2150.0\n",
      "VERSION:  v3\n",
      "cl Supported\n",
      "num 3000.0\n",
      "cl Unsupported\n",
      "num 3000.0\n",
      "cl Grooming\n",
      "num 2000.0\n",
      "VERSION:  v4\n",
      "cl Supported\n",
      "num 3000.0\n",
      "cl Unsupported\n",
      "num 3000.0\n",
      "cl Grooming\n",
      "num 1900.0\n",
      "VERSION:  v5\n",
      "cl Supported\n",
      "num 3000.0\n",
      "cl Unsupported\n",
      "num 3000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "GOAL:  4000\n",
      "VERSION:  v1\n",
      "cl Supported\n",
      "num 4000.0\n",
      "cl Unsupported\n",
      "num 4000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v2\n",
      "cl Supported\n",
      "num 4000.0\n",
      "cl Unsupported\n",
      "num 4000.0\n",
      "cl Grooming\n",
      "num 2000.0\n",
      "VERSION:  v3\n",
      "cl Supported\n",
      "num 4000.0\n",
      "cl Unsupported\n",
      "num 4000.0\n",
      "cl Grooming\n",
      "num 2000.0\n",
      "VERSION:  v4\n",
      "cl Supported\n",
      "num 4000.0\n",
      "cl Unsupported\n",
      "num 4000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v5\n",
      "cl Supported\n",
      "num 4000.0\n",
      "cl Unsupported\n",
      "num 4000.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "GOAL:  5000\n",
      "VERSION:  v1\n",
      "cl Supported\n",
      "num 5000.0\n",
      "cl Unsupported\n",
      "num 4500.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v2\n",
      "cl Supported\n",
      "num 5000.0\n",
      "cl Unsupported\n",
      "num 4750.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v3\n",
      "cl Supported\n",
      "num 5000.0\n",
      "cl Unsupported\n",
      "num 4600.0\n",
      "cl Grooming\n",
      "num 2250.0\n",
      "VERSION:  v4\n",
      "cl Supported\n",
      "num 5000.0\n",
      "cl Unsupported\n",
      "num 4650.0\n",
      "cl Grooming\n",
      "num 1950.0\n",
      "VERSION:  v5\n",
      "cl Supported\n",
      "num 5000.0\n",
      "cl Unsupported\n",
      "num 4600.0\n",
      "cl Grooming\n",
      "num 1900.0\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "chunk_size = 50\n",
    "# save dfs as np arrays\n",
    "names = ['Background','Supported','Unsupported','Grooming']\n",
    "\n",
    "# main loop\n",
    "#goals = [50, 100, 250, 500, 1000]\n",
    "goals = [2000, 3000, 4000, 5000]\n",
    "vs = ['v1', 'v2', 'v3', 'v4', 'v5']\n",
    "seeds = [1, 1001, 2001, 3001, 4001]\n",
    "\n",
    "#v = 'v1'\n",
    "#goal = 500\n",
    "\n",
    "for goal in goals:\n",
    "    print('GOAL: ', goal)\n",
    "    for v, seed in zip(vs, seeds):\n",
    "        print('VERSION: ', v)\n",
    "        labels_int = []\n",
    "        for df in train_dfs:\n",
    "            temp = np.zeros(df.shape[0])\n",
    "            \n",
    "            # convert from 1-hot vector\n",
    "            inds = list(df.idxmax(axis=1))\n",
    "            \n",
    "            # convert to label name\n",
    "            np_inds = np.array([names.index(i) for i in inds])\n",
    "\n",
    "            labels_int.append(np_inds)\n",
    "\n",
    "        classes = ['Supported', 'Unsupported', 'Grooming']\n",
    "        \n",
    "        # keeps track of num labels per class\n",
    "        num_labeled = np.zeros(len(classes))\n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "        # create array to hold new labels - for all the train dfs\n",
    "        new_labels = [np.zeros_like(a) for a in labels_int]\n",
    "\n",
    "\n",
    "        # iterate through classes\n",
    "        for c, cl in enumerate(classes):\n",
    "            print('cl', cl)\n",
    "            tries = 0\n",
    "            # keep adding labeled chunks until we reach goal\n",
    "            while num_labeled[c] < goal:\n",
    "                random.seed(seed)\n",
    "\n",
    "                # choose a video and update seed\n",
    "                vid = random.randint(0, len(train_vids)-1)\n",
    "                seed += 1\n",
    "                \n",
    "                # pulling the ground truth classes\n",
    "                arr = labels_int[vid]\n",
    "\n",
    "                # choose index  \n",
    "                labels, starts, ends, lens = get_labels_start_end_time(np.array(arr), bg_class=[0], use=(c+1),chunk_size=chunk_size)\n",
    "\n",
    "                # create list of all valid start inds\n",
    "                start_inds = []\n",
    "                for s,e in zip(starts, ends):\n",
    "                    start_inds += list(range(s,e))\n",
    "\n",
    "                # pick a start index\n",
    "                random.seed(seed)\n",
    "                if len(start_inds) < 1:\n",
    "                    tries += 1\n",
    "                    if tries > 100:\n",
    "                        break\n",
    "                    continue\n",
    "                si_ind = random.randint(0, len(start_inds)-1)\n",
    "                seed += 1\n",
    "                \n",
    "                # chosen start index\n",
    "                si = start_inds[si_ind]\n",
    "\n",
    "                # update new labels array\n",
    "                new_labels[vid][si:si+chunk_size] = (c+1)\n",
    "\n",
    "                # remove chose indexes from list of possible inds\n",
    "                labels_int[vid][si:si+chunk_size] = 0\n",
    "\n",
    "                # update num labeled\n",
    "                num_labeled[c] += chunk_size\n",
    "   \n",
    "            print('num', num_labeled[c])\n",
    "\n",
    "        # create df based on new labels and save\n",
    "        new_dfs = []\n",
    "        for arr in new_labels:\n",
    "            lab_np = np.zeros((len(arr), len(names)))\n",
    "            for ind, l in enumerate(arr):\n",
    "                lab_np[ind, l] = 1\n",
    "            lab_df = pd.DataFrame(lab_np, dtype=int)\n",
    "            new_dfs.append(lab_df)\n",
    "\n",
    "        # save labels\n",
    "        # format of file - 'sess_' + s + '_' + num_labels + '_' + seed version + '_labels.csv'\n",
    "        # i.e. sess_05_500_v1_labels.csv\n",
    "        for d, df in enumerate(new_dfs):\n",
    "            lab_path = path + '/' + train_vids[d] + '_' + str(goal) + '_' + v + '_labels.csv'\n",
    "            df.columns = names\n",
    "            df.to_csv(lab_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daart2",
   "language": "python",
   "name": "daart2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
